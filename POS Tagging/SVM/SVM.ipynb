{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rfc-AIE8xyBT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "outputId": "5f860dbf-68b5-4662-bb85-b557c9b6a092"
      },
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n",
        "from nltk.stem.porter import *\n",
        " \n",
        "stemmer = PorterStemmer() \n",
        "\n",
        "data = nltk.corpus.brown.tagged_sents(tagset='universal')\n",
        "\n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "y_train_lab = []\n",
        "dict_lab = {'VERB':0,'NOUN':1,'PRON':2,'ADJ':3,'ADV':4,'DET':5,'ADP':6,'PRT':7,'NUM':8,'CONJ':9,'X':10,'.':11}\n",
        "lis_noun_suff = ['acy','al','ance','ence','dom','er','or','ism','ist','ity','ty','ment','ness','ship','tion','sion']\n",
        "lis_verb_suff = ['ate','en','ify','fy','ize','ise','ed','ing','in','ted']\n",
        "lis_adv_suff = ['ly','ward','wise']\n",
        "lis_adj_suff = ['able','ible','al','esque','ful','ic','ical','ious','ous','ish','ive','less','y']\n",
        "lis_pref = []\n",
        "#Data Retrieval\n",
        "for i in range(len(data)):\n",
        "  x_train.append([0] *len(data[i]))\n",
        "  for j in range(len(data[i])):\n",
        "    x_train[i][j] = data[i][j][0]\n",
        "for i in range(len(data)):\n",
        "  y_train.append([0] *len(data[i]))\n",
        "  y_train_lab.append([0] *len(data[i]))\n",
        "  for j in range(len(data[i])):\n",
        "    y_train[i][j] = data[i][j][1]\n",
        "    y_train_lab[i][j] = dict_lab[y_train[i][j]]\n",
        "print(y_train_lab[1])    \n",
        "set1 = []\n",
        "set2 = []\n",
        "set3 = []\n",
        "set4 = []\n",
        "set5 = []\n",
        "print(x_train[0])\n",
        "from gensim.test.utils import common_texts, get_tmpfile\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
            "[5, 1, 4, 0, 6, 1, 1, 6, 5, 1, 3, 1, 11, 5, 0, 3, 1, 6, 5, 1, 11, 11, 0, 5, 1, 9, 1, 6, 5, 1, 6, 1, 11, 6, 5, 1, 6, 5, 5, 1, 0, 0, 11]\n",
            "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmFUDx6ToUCP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "2300f5b0-e265-45d0-d0bc-a2caa17bdaa1"
      },
      "source": [
        "print(len(x_train))\n",
        "model = Word2Vec(x_train, min_count=1)\n",
        "print(model)\n",
        "words = list(model.wv.vocab)\n",
        "print(len(words))\n",
        "print(model['sentence'])\n",
        "model.save('model.bin')\n",
        "new_model = Word2Vec.load('model.bin')\n",
        "print(new_model)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "57340\n",
            "Word2Vec(vocab=56057, size=100, alpha=0.025)\n",
            "56057\n",
            "[-0.33918092 -0.18236215 -0.06366342 -0.04917064  0.06220258  0.10781239\n",
            " -0.15135922 -0.02708047  0.05228844 -0.27780905 -0.1129632   0.11057752\n",
            " -0.04243162  0.08352098  0.21717949 -0.04830721 -0.30595952  0.06179826\n",
            " -0.09689933  0.10928553  0.11445364 -0.05214125 -0.12543702 -0.039135\n",
            " -0.0154671  -0.02786046 -0.07560717  0.09233151  0.17446154  0.03005295\n",
            " -0.08444139 -0.0099549   0.02158443 -0.1343606  -0.07812148 -0.09670448\n",
            " -0.17395076  0.06044216 -0.09556395 -0.02534168  0.01098322  0.21938924\n",
            " -0.18252148 -0.14462712  0.00305293 -0.16116913 -0.0040987  -0.13805375\n",
            " -0.0709253   0.02666218  0.0267207  -0.0916956  -0.06199643  0.05051552\n",
            " -0.25731525  0.01527102  0.02401916  0.11720204 -0.2963203   0.05477145\n",
            " -0.27072522 -0.18837035  0.08387445  0.15255482 -0.24212393  0.14482433\n",
            " -0.11507333 -0.14675184  0.12114433  0.09802779  0.00821213 -0.02036013\n",
            " -0.02373908  0.03876213  0.09471643 -0.32365292 -0.03617456 -0.13649336\n",
            " -0.27478814  0.23083729 -0.2672816   0.19777316 -0.07056428  0.03131286\n",
            "  0.06830686 -0.13903074 -0.01051304  0.11053686 -0.3940284   0.09592223\n",
            " -0.03402074 -0.14100286 -0.04694477  0.16162361 -0.14550975  0.14561613\n",
            "  0.01621987  0.11122196 -0.05319228 -0.1765414 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=56057, size=100, alpha=0.025)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PyVbMwqpBte",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "702a664e-2f0d-4469-8879-fe706db75f23"
      },
      "source": [
        "print(new_model['hello'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.01123225  0.01901769 -0.05012141  0.03500541  0.05238076 -0.00227565\n",
            " -0.00388959 -0.04546586  0.02150985 -0.00508514  0.0327998  -0.01595703\n",
            " -0.00011808 -0.00598786 -0.01781725  0.00817285 -0.00058008  0.02323628\n",
            "  0.00342205  0.0004929   0.03042234  0.02818235  0.01313855 -0.0117139\n",
            " -0.02404194 -0.026666   -0.00237716 -0.01320647 -0.02183941 -0.00631138\n",
            "  0.05788204  0.03221546 -0.0242414   0.00629405  0.0172993   0.01012459\n",
            "  0.02262609 -0.01046334  0.00637312  0.01019726 -0.0183421   0.0286013\n",
            " -0.00011945 -0.0145191   0.02132571 -0.00545667  0.016617   -0.02263842\n",
            "  0.00704964  0.00071821 -0.02137304  0.00889489 -0.00037711  0.00113791\n",
            " -0.02293999  0.01711051 -0.00624962 -0.00105798 -0.00268561  0.02062534\n",
            " -0.01220869  0.03601736 -0.01916738  0.04356102  0.0318234  -0.03102652\n",
            " -0.03291371  0.01691806 -0.01284643 -0.03520473  0.00047578 -0.02551163\n",
            " -0.01590709  0.02846574  0.00480842  0.01827095 -0.01667361  0.04395735\n",
            "  0.02921761 -0.00386927 -0.02035214 -0.01863474  0.01071067 -0.00324369\n",
            " -0.00075228 -0.02511482  0.02627617  0.00608678  0.03381418 -0.0004695\n",
            " -0.01012489  0.00238015  0.05095873 -0.02131969  0.03553467 -0.00391464\n",
            " -0.00139788  0.01137429 -0.00340431  0.02474785]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwV12ewirWKo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a265bc8d-cf79-4661-d64e-e0ef82bcefd2"
      },
      "source": [
        "y_onehot = []\n",
        "print(y_train_lab[5000])\n",
        "for i in range(len(y_train_lab)):\n",
        "  k = []\n",
        "  for j in range(len(y_train_lab[i])):\n",
        "    k.append([0]*12) \n",
        "  for j in range(len(y_train_lab[i])):\n",
        "    k[j][y_train_lab[i][j]] = 1\n",
        "  y_onehot.append(k)\n",
        "  \n",
        "print((y_onehot[1][4])) "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8, 11]\n",
            "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waXO_mcJx6qb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "a39a6335-d7a0-416e-f335-2d1a69453f6c"
      },
      "source": [
        "#Data Preprocessing\n",
        "case_vec = []  \n",
        "for i in range(len(x_train)):\n",
        "  kk = np.zeros([len(x_train[i]),10])\n",
        "  word_vec = np.zeros([len(x_train[i]),110])\n",
        "  for j in range(len(x_train[i])):\n",
        "    word = x_train[i][j]\n",
        "    temp = 0\n",
        "    temp = ord(word[0])\n",
        "    temp2 = -5\n",
        "    temp3 = -5\n",
        "    if(len(word)>2):\n",
        "      temp2 = ord(word[len(word)-2])\n",
        "      temp3 = ord(word[len(word)-3])\n",
        "    flag = 0\n",
        "    flag2 = 0\n",
        "    verb_flag = 0\n",
        "    len_flag = 0\n",
        "    poss_flag = 0\n",
        "    #Suffix\n",
        "    bi_suf = word[len(word)-2:len(word)]\n",
        "    tri_suf = word[len(word)-3:len(word)]\n",
        "    four_suf = word[len(word)-4:len(word)]\n",
        "    stem = stemmer.stem(word)\n",
        "    if((bi_suf in lis_adj_suff or tri_suf in lis_adj_suff or four_suf in lis_adj_suff) and stem!=word):\n",
        "      kk[j][5] = 1\n",
        "      # print(\"adj \",word)\n",
        "    elif((bi_suf in lis_noun_suff or tri_suf in lis_noun_suff or four_suf in lis_noun_suff) and stem!=word):\n",
        "      kk[j][6] = 1\n",
        "      # print(\"noun \",word)\n",
        "    elif((bi_suf in lis_adv_suff or tri_suf in lis_adv_suff or four_suf in lis_adv_suff) and stem!=word):\n",
        "      kk[j][7] = 1  \n",
        "      flag2 = 1\n",
        "      # print(\"adverb \",word)   \n",
        "    elif((bi_suf in lis_verb_suff or tri_suf in lis_verb_suff or four_suf in lis_verb_suff) and stem!=word):\n",
        "      kk[j][8] = 1\n",
        "      verb_flag = 1\n",
        "      # print(\"verb \",word)\n",
        "\n",
        "    #Check Hyphen\n",
        "    for jj in range(len(word)-1):\n",
        "      if(ord(word[jj])==45 and ord(word[jj+1])!=45):\n",
        "        kk[j][4] = 1 \n",
        "        flag = 1\n",
        "        # print(word)\n",
        "        break\n",
        "    #Check Number\n",
        "    if(temp<=57 and temp >=47):\n",
        "      kk[j][0] = 1\n",
        "    #Check Full Cap   \n",
        "    # elif(temp2<=90 and temp2>=65):\n",
        "      # kk[j][1] = 1\n",
        "    #Check First Upper Cap \n",
        "    if(temp<=90 and temp>=65):\n",
        "      kk[j][1] = 1 \n",
        "    #Check LOwer Cap  \n",
        "    if(len(word)<=3):\n",
        "      kk[j][2] = 1 \n",
        "      len_flag = 1\n",
        "    if(temp2==39 or temp3==39): \n",
        "      # print(word)\n",
        "      kk[j][9] = 1\n",
        "      poss_flag = 1\n",
        "    if((temp==46 or temp==96 or temp==95 or temp ==94 or temp==58 or temp ==59 or temp ==33 or temp==34  or temp ==44)):\n",
        "      kk[j][3] = 1  \n",
        " \n",
        "    word_vec[j][:100] = new_model[word] \n",
        "    word_vec[j][100:110] = kk[j]\n",
        "\n",
        "\n",
        "  case_vec.append(word_vec)\n",
        "\n",
        "print(case_vec[0][0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:67: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[-0.53048486 -0.79499507  0.66279495 -0.86621833 -1.79288244 -0.77798808\n",
            " -0.76155883  0.52823228 -0.65571135 -1.54556024 -2.17850757  0.66010869\n",
            "  0.34099823  0.23097049  1.20701289  0.41144201 -0.4908649   0.26935008\n",
            "  0.56168938  1.20637226  0.80144978 -0.42967144  0.25884387 -0.46526155\n",
            "  0.6172061   0.3332262  -0.4768194  -0.21207659  1.57366943 -0.14093094\n",
            " -1.15857112 -0.36763316  0.62378317 -0.44048423 -0.54244119  0.03927876\n",
            " -0.87010175  0.25786752  0.82037008 -0.45164153  0.05719548 -0.69351912\n",
            "  0.24891345 -1.49566185 -1.33838153 -1.47561347 -0.01864672  0.1507317\n",
            " -1.29313624 -1.24699843 -0.44354847 -0.35987419 -2.03279328 -1.68029106\n",
            " -0.47505051 -0.4866153  -0.12439436  0.14458936 -1.53257     0.57551879\n",
            " -1.29932809 -1.24353802 -0.58347958  1.79230428 -2.00593042  0.30954236\n",
            "  2.1757946  -0.96728963 -0.72513014  1.42733037  0.69470644 -0.78746647\n",
            " -0.16032042 -1.6682775   1.64269376 -0.52216154  1.07895923 -0.99151617\n",
            "  0.5383417   2.88176274 -0.55913311  0.88645935  0.62853086 -0.34226474\n",
            "  0.35015318  0.24486855 -0.64792109  0.80003482 -0.49237815 -1.71391773\n",
            "  0.10996999  1.11106372 -1.32589197 -0.54309642 -1.30565214  1.87294638\n",
            " -0.25886738 -0.37295157 -0.11161412 -1.10386956  0.          1.\n",
            "  1.          0.          0.          0.          0.          0.\n",
            "  0.          0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg4SLrWEvrJ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "1669cc1f-e99a-4e8e-8c2c-1d6c52c9e5d4"
      },
      "source": [
        "print(len(case_vec[0][0]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "110\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfgIa1_NzCkP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "af816c11-d42e-4b69-e2b0-b7893405c962"
      },
      "source": [
        " case_vec2 = []\n",
        " for i in range(len(case_vec)):\n",
        "   word_vec2 = np.zeros([len(case_vec[i]),330])\n",
        "   for j in range(len(case_vec[i])):\n",
        "     word_vec2[j][:110] =  case_vec[i][j]      \n",
        "     if(j>0 and j!=len(case_vec[i])-1):\n",
        "      word_vec2[j][110:220] =  case_vec[i][j-1]\n",
        "     if(j>=0 and j!=len(case_vec[i])-1):\n",
        "      word_vec2[j][220:330] =  case_vec[i][j+1]\n",
        "   case_vec2.append(word_vec2)    \n",
        "print(case_vec2[0][0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-5.30484855e-01 -7.94995070e-01  6.62794948e-01 -8.66218328e-01\n",
            " -1.79288244e+00 -7.77988076e-01 -7.61558831e-01  5.28232276e-01\n",
            " -6.55711353e-01 -1.54556024e+00 -2.17850757e+00  6.60108685e-01\n",
            "  3.40998232e-01  2.30970487e-01  1.20701289e+00  4.11442012e-01\n",
            " -4.90864903e-01  2.69350082e-01  5.61689377e-01  1.20637226e+00\n",
            "  8.01449776e-01 -4.29671437e-01  2.58843869e-01 -4.65261549e-01\n",
            "  6.17206097e-01  3.33226204e-01 -4.76819396e-01 -2.12076589e-01\n",
            "  1.57366943e+00 -1.40930936e-01 -1.15857112e+00 -3.67633164e-01\n",
            "  6.23783171e-01 -4.40484226e-01 -5.42441189e-01  3.92787643e-02\n",
            " -8.70101750e-01  2.57867515e-01  8.20370078e-01 -4.51641530e-01\n",
            "  5.71954809e-02 -6.93519115e-01  2.48913452e-01 -1.49566185e+00\n",
            " -1.33838153e+00 -1.47561347e+00 -1.86467227e-02  1.50731698e-01\n",
            " -1.29313624e+00 -1.24699843e+00 -4.43548471e-01 -3.59874189e-01\n",
            " -2.03279328e+00 -1.68029106e+00 -4.75050509e-01 -4.86615300e-01\n",
            " -1.24394357e-01  1.44589365e-01 -1.53257000e+00  5.75518787e-01\n",
            " -1.29932809e+00 -1.24353802e+00 -5.83479583e-01  1.79230428e+00\n",
            " -2.00593042e+00  3.09542358e-01  2.17579460e+00 -9.67289627e-01\n",
            " -7.25130141e-01  1.42733037e+00  6.94706440e-01 -7.87466466e-01\n",
            " -1.60320416e-01 -1.66827750e+00  1.64269376e+00 -5.22161543e-01\n",
            "  1.07895923e+00 -9.91516173e-01  5.38341701e-01  2.88176274e+00\n",
            " -5.59133112e-01  8.86459351e-01  6.28530860e-01 -3.42264742e-01\n",
            "  3.50153178e-01  2.44868547e-01 -6.47921085e-01  8.00034821e-01\n",
            " -4.92378145e-01 -1.71391773e+00  1.09969988e-01  1.11106372e+00\n",
            " -1.32589197e+00 -5.43096423e-01 -1.30565214e+00  1.87294638e+00\n",
            " -2.58867383e-01 -3.72951567e-01 -1.11614123e-01 -1.10386956e+00\n",
            "  0.00000000e+00  1.00000000e+00  1.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            " -1.11539200e-01 -6.88557476e-02 -4.77160048e-03  1.97452195e-02\n",
            " -5.97886294e-02  5.15615754e-02  1.48765091e-03 -3.98809426e-02\n",
            " -1.88227501e-02 -1.94757119e-01 -4.01899070e-02  1.03513889e-01\n",
            " -1.82632245e-02  7.79330209e-02  1.04266971e-01 -4.65666242e-02\n",
            " -1.50545448e-01  3.17810960e-02 -3.33741233e-02  5.06680533e-02\n",
            "  9.81687009e-03  2.33471133e-02 -4.93157208e-02  4.84033115e-02\n",
            "  3.40281590e-03 -1.09182760e-01 -9.13011804e-02  6.63086548e-02\n",
            "  1.28709096e-02 -5.19022569e-02 -2.05522850e-02 -5.72001040e-02\n",
            "  3.10601573e-02 -1.20911002e-02 -4.96493019e-02 -5.12919277e-02\n",
            " -9.15806442e-02  3.12781930e-02  1.37881655e-02 -7.58586824e-02\n",
            " -3.96863259e-02  6.57360405e-02 -2.10025199e-02 -8.47890452e-02\n",
            "  1.93423051e-02 -5.31943403e-02 -3.31355743e-02 -5.62361851e-02\n",
            " -4.56999391e-02  2.92670727e-02  3.48519273e-02 -3.56206112e-02\n",
            " -4.99581248e-02 -1.87408775e-02 -1.67767275e-02 -3.47979330e-02\n",
            " -6.32367730e-02  9.79466885e-02 -1.34454697e-01  4.02111374e-02\n",
            " -6.04054965e-02 -3.11209876e-02  2.58708149e-02  1.01192832e-01\n",
            " -2.09769711e-01  1.09049901e-02 -4.69400287e-02 -6.01973198e-03\n",
            "  7.08061978e-02  8.83027986e-02  8.69557559e-02 -3.10551352e-03\n",
            " -2.84785051e-02  2.08064867e-03  1.00995846e-01 -8.69620144e-02\n",
            "  2.61770356e-02 -3.14539149e-02 -6.13422170e-02  1.17225379e-01\n",
            " -2.29712110e-02  6.81833029e-02 -5.83910905e-02 -4.07294407e-02\n",
            " -5.91414161e-02  3.87833640e-02  7.74436742e-02  2.65214480e-02\n",
            " -1.26613840e-01 -7.74866641e-02 -3.95432077e-02 -7.32175261e-02\n",
            " -1.69539768e-02  8.28973725e-02 -6.18705824e-02  3.65396291e-02\n",
            " -3.59924510e-02 -6.02098939e-04 -2.41528489e-02 -1.14959881e-01\n",
            "  0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wX_SEi5v2DQ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "52b37213-13cc-4e8a-9471-ea9c9e6d7e5c"
      },
      "source": [
        "flatList = [ item for elem in case_vec2 for item in elem]\n",
        "flatList2 = [ item for elem in y_train_lab for item in elem]\n",
        "flatList3 = [ item for elem in x_train for item in elem]\n",
        "print(flatList3[0])\n",
        "print(len(flatList[0]))\n",
        "print(flatList2[0])\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The\n",
            "330\n",
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyOlXHuA_YYy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e8c507d6-f603-44ee-b85e-0af3a7401798"
      },
      "source": [
        "from tempfile import TemporaryFile\n",
        "\n",
        "with open('f1.npy', 'wb') as f1:\n",
        "    np.save(f1, flatList)\n",
        "with open('f2.npy', 'wb') as f2:\n",
        "    np.save(f2, flatList2)\n",
        "with open('f3.npy', 'wb') as f3:\n",
        "    np.save(f3, flatList3)        \n",
        "with open('f1.npy', 'rb') as f4:\n",
        "    a = np.load(f4)\n",
        "print(a.shape)    "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1161192, 330)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDlFAPyNEjT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "with open('f1.npy', 'rb') as f4:\n",
        "  a = np.load(f4) \n",
        "with open('f2.npy', 'rb') as f5:\n",
        "  b = np.load(f5)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1ziz4_B4Jhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(zz, X):\n",
        "  probs = np.dot(X, zz)\n",
        "  pred = probs.argmax(axis=1)\n",
        "  return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpzmeYogzARW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "42afb226-9f7d-4e1d-9ab6-e42154179455"
      },
      "source": [
        "\n",
        "#SVM Algo\n",
        "import numpy as np\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from numpy import linalg as LA\n",
        "def train(x_train,y_train):\n",
        "  alpha = np.zeros((12,x_train.shape[0]),dtype=np.float64)\n",
        "  weights = np.zeros((12,x_train.shape[1]),dtype=np.float64)\n",
        "  threshold = 0.00001\n",
        "  v_max = -1000000\n",
        "  iter = 0\n",
        "  v_avg = 0\n",
        "  while((v_avg>threshold or (iter==0)) and  iter<20):\n",
        "    vsum = 0\n",
        "    for i in range(x_train.shape[0]):\n",
        "      margin = np.ones((12))\n",
        "      margin[y_train[i]] = 0\n",
        "      C_matrix = np.zeros((12))\n",
        "      C_matrix[y_train[i]] = 1\n",
        "\n",
        "      grad = np.dot(x_train[i],weights.T) + margin\n",
        "    \n",
        "      vv = grad.max()-grad[alpha[:,i]<C_matrix].min()\n",
        "   \n",
        "      \n",
        "      vsum = vsum + vv\n",
        "\n",
        "      if(vv>0.00000001):\n",
        "        x_norm = LA.norm(x_train[i])\n",
        "  \n",
        "        bet = x_norm*(C_matrix - alpha[:,i]) + (grad)/(x_norm)\n",
        "        Low = 0\n",
        "        Up = np.max(bet)\n",
        "        s= np.inf\n",
        "        maxi = 0\n",
        "        while((np.abs(s/x_norm)>0.0001 or s>=0) and maxi<=1000):\n",
        "          theta = (Low + Up)/2\n",
        "          s =  np.sum(np.maximum(bet - theta,0)) - x_norm \n",
        "          maxi = maxi + 1\n",
        "          if s <= 0:\n",
        "            Up = theta\n",
        "          else:\n",
        "            Low = theta\n",
        "        \n",
        "          \n",
        "        Del = C_matrix - alpha[:,i] - (np.maximum(bet - theta,0))/x_norm\n",
        "        \n",
        "        \n",
        "        alpha[:,i] = alpha[:,i] + Del\n",
        "        weights = weights + np.dot(Del.reshape(12,1),x_train[i].reshape(1,x_train.shape[1]))\n",
        "      \n",
        "        \n",
        "    if(iter ==0):\n",
        "      vinit = vsum  \n",
        "    print(vinit)\n",
        "    print(vsum)  \n",
        "    v_avg = vsum/vinit  \n",
        "    print(v_avg)    \n",
        "    print(\"iter\",iter)\n",
        "    iter=iter+1\n",
        "  return weights  \n",
        "if __name__ == '__main__':\n",
        "\n",
        "    print(a.shape)\n",
        "    print(b.shape)\n",
        "\n",
        "    from sklearn.model_selection import KFold\n",
        "    kfold = KFold(5, True, 1)\n",
        "    fin_pred = []\n",
        "    test_lab = []\n",
        "    for train1, test1 in kfold.split(a,b):\n",
        "      print(a[train1].shape)\n",
        "      print(type(a[test1]))\n",
        "      weigh = train(a[train1],b[train1])\n",
        "      fin_pred.append(test(weigh.T, a[test1]))\n",
        "      test_lab.append(b[test1])\n",
        "    print(d[:6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1161192, 330)\n",
            "(1161192,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUTVpKZUX3ph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Testing\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(figsize=(12,12))\n",
        "Acc = np.zeros((5))\n",
        "for i in range(5):\n",
        "  for j in range(len(test_lab[i])):\n",
        "    if(test_lab[i][j]==fin_pred[i][j]):\n",
        "      Acc[i] = Acc[i]+1\n",
        "  Acc[i] = Acc[i]/len(test_lab[i])\n",
        "print(\"5 fold Acc\",Acc) \n",
        "print(\"Avg Accuracy\",np.sum(Acc)/5)     \n",
        "y_pred = np.array(list(itertools.chain.from_iterable(fin_pred)))\n",
        "y_tr = np.array(list(itertools.chain.from_iterable(test_lab)))\n",
        "  \n",
        "mat = confusion_matrix(y_tr, y_pred, labels=[0,1,2,3,4,5,6,7,8,9,10,11])\n",
        "\n",
        "labels=['VERB','NOUN','PRON','ADJ','ADV','DET','ADP','PRT','NUM','CONJ','X','END']\n",
        "ax.matshow(mat, cmap=plt.cm.Blues)\n",
        "lis = [-1,0,1,2,3,4,5,6,7,8,9,10,11]\n",
        "ax.set_xticks(lis)\n",
        "ax.set_yticks(lis)\n",
        "ax.set_xticklabels([''] + labels)\n",
        "ax.set_yticklabels([''] + labels)\n",
        "for i in range(12):\n",
        "  for j in range(12):\n",
        "    c = mat[j,i]\n",
        "    ax.text(i, j, str(c), va='bottom', ha='center')\n",
        "    ax.text(i,j,str(round((c/mat.sum()*100),2))+\"%\",va='top', ha='center')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "per_Pos = np.zeros((12))    \n",
        "for i in range(12):\n",
        "  per_Pos[i] = mat[i][i]/np.sum(mat[i])\n",
        "print(\"per_pos\",per_Pos)     \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
